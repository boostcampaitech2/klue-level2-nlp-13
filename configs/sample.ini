[Path]
data_path = ../dataset/train/train.csv
test_data_path = ../dataset/test/test.csv
label_to_num = ./dict_label_to_num.pkl
num_to_label = ./dict_num_to_label.pkl
model_save_path = ./best_model/test_roberta
output_dir = ./results
logging_dir = ./logs
submission_file_name = base_roberta.csv

[Model]
model_name = klue/roberta-large
tokenizer_name = klue/roberta-large
optimizer_name = AdamW
scheduler_name = CosineAnnealingLR
num_classes = 30
add_special_token = False

[Loss]
loss_name = CrossEntropy_weighted
loss1_weight = 0.9
loss2_weight = 0.1

[Training]
num_train_epochs = 5
learning_rate = 5e-5
batch_size = 64
warmup_steps = 500
weight_decay = 0.01
early_stopping = 5
k_fold_num = 5
random_state= 42

[Recording]
logging_steps = 100
save_total_limit = 5
save_steps = 500
evaluation_strategy = steps
eval_steps = 500

[WandB]
run_name = base_line_roberta
project = 'YJH'
entity = 'clue'

[Etc]
seed = 42
