[Path]
data_path = ../dataset/train/train.csv
test_data_path = ../dataset/test/test_data.csv
label_to_num = ./dict_label_to_num.pkl
num_to_label = ./dict_num_to_label.pkl
model_save_path = ./best_model/seed105_roberta-large_batch_16
output_dir = ./results
logging_dir = ./logs
submission_file_name = submission_seed105_roberta-large_batch_16.csv

[Model]
model_name = /opt/ml/code/best_model/roberta-large-pretrained
tokenizer_name = klue/roberta-large
optimizer_name = AdamW
scheduler_name = CosineAnnealingLR
num_classes = 30
add_special_token = True
new_special_token_list = ['@','^','*','#']

[Loss]
loss_name = CrossEntropy
loss1_weight = 0.9
loss2_weight = 0.1

[Training]
num_train_epochs = 15
learning_rate = 1e-5
batch_size = 16
warmup_steps = 500
weight_decay = 0.01
early_stopping = 1
k_fold_num = 5
random_state= 105

[Recording]
logging_steps = 100
save_total_limit = 5
save_steps = 500
evaluation_strategy = steps
eval_steps = 500

[WandB]
run_name = YJH_batch16_seed105_epoch20
project = SIAUN
entity = clue

[Etc]
seed = 105
