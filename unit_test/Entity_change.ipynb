{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2d7bf28-a6c5-4aa4-ab92-62a173057b50",
   "metadata": {},
   "source": [
    "# 엔티티만 변경, 다른 부분은 고정!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41afe494-14c5-4f32-9c58-d900100b67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4893c3f1-c6fb-4d31-8317-aa58cb6d0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 안에서 원하는 tpye의 entity 리스트 추출\n",
    "    # PER, LOC, NOH, ORG, DAT, \n",
    "def extract_entity_based_on_type(data, entity, type_, save_name):\n",
    "    et = {'name':[], 'type':[]}\n",
    "    for dic in data[entity].values:\n",
    "        dic = literal_eval(dic)\n",
    "\n",
    "        if dic['type'] == type_:\n",
    "            et['name'].append(dic['word'])\n",
    "\n",
    "    names = list(set(et['name']))\n",
    "    et['name'] = names\n",
    "    et['type'] = [type_ for _ in range(len(names))]\n",
    "    et = pd.DataFrame(et)\n",
    "    #et.to_csv(save_name+'.csv', index=False)\n",
    "    \n",
    "    return et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a491cf49-d84e-41c9-b9a2-eacd5a873be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence 변경\n",
    "def change_sentence(text, sx, ex, sy, ey, first_word, second_word):\n",
    "    # entity 위치만 제거 하고 새로운 entity 삽입\n",
    "    sentence = text[:sx] + first_word + text[ex+1:sy] + second_word + text[ey+1:]\n",
    "    # 새로운 좌표계산\n",
    "    origin_length = ex - sx + 1 \n",
    "    ex = sx + len(first_word) - 1  # 길이를 이용해 끝점 계산\n",
    "    sy = sy + (len(first_word) - origin_length) # 길면 +, 짧으면 - 해서 시작위치 조절\n",
    "    ey = sy + len(second_word) - 1 # 길이를 이용해 끝점 계산\n",
    "    \n",
    "    return sentence, sx, ex, sy, ey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ea8dbcd7-fa4e-47dd-8e22-d7c9639c2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(target_df, sub_entity_list, obj_entity_list, target_class, times, save_name):\n",
    "    new = {'id':[], 'sentence':[], 'subject_entity':[], 'object_entity':[], 'label':[], 'source':[]}\n",
    "    \n",
    "    # 원본 데이터수 * times 개 생성\n",
    "    for time in range(times):\n",
    "        for idx, (id_, sentence, subject_entity, object_entity, label, source) in enumerate(target_df.values):\n",
    "            # 정보 추출\n",
    "            subject_dict = literal_eval(subject_entity)\n",
    "            object_dict = literal_eval(object_entity)\n",
    "\n",
    "            # 랜덤 추출\n",
    "            sub_idx = np.random.randint(0, sub_entity_list.shape[0])\n",
    "            obj_idx = np.random.randint(0, obj_entity_list.shape[0])\n",
    "            sub_word = sub_entity_list['name'].iloc[sub_idx]\n",
    "            obj_word = obj_entity_list['name'].iloc[obj_idx]\n",
    "\n",
    "            # Sentence 바꾸기\n",
    "                # 먼저 나오는 entity 속성에 따라 입력 값, 반환 값 순서를 다르게!\n",
    "            if subject_dict['start_idx'] > object_dict['start_idx']:\n",
    "                new_sentence, sy, ey, sx, ex = change_sentence(sentence, object_dict['start_idx'], object_dict['end_idx'], subject_dict['start_idx'], subject_dict['end_idx'], obj_word, sub_word)\n",
    "            else:\n",
    "                new_sentence, sx, ex, sy, ey = change_sentence(sentence, subject_dict['start_idx'], subject_dict['end_idx'], object_dict['start_idx'], object_dict['end_idx'], sub_word, obj_word)\n",
    "\n",
    "            # subject_entity//object_entity 새로운 정보 입력\n",
    "            subject_dict['word'] = sub_word\n",
    "            subject_dict['start_idx'] = sx\n",
    "            subject_dict['end_idx'] = ex\n",
    "\n",
    "            object_dict['word'] = obj_word\n",
    "            object_dict['start_idx'] = sy\n",
    "            object_dict['end_idx'] = ey\n",
    "\n",
    "            new['id'].append(id_)\n",
    "            new['sentence'].append(new_sentence)\n",
    "            new['subject_entity'].append(str(subject_dict)) # string으로 변환해 입력\n",
    "            new['object_entity'].append(str(object_dict)) # string으로 변환해 입력\n",
    "            new['label'].append(label)\n",
    "            new['source'].append(source) \n",
    "\n",
    "    # 데이터 프레임으로 변경\n",
    "    new = pd.DataFrame(new)\n",
    "    # 문장 기준 중복제거\n",
    "    new = new.drop_duplicates('sentence')\n",
    "    print(\"생성된 데이터 수:\", new.shape)\n",
    "    #new.to_csv('./entity_change_data/new_'+target_class+'_members.csv', index=False)\n",
    "    new.to_csv('./entity_change_data/' + save_name , index=False)\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64a69a38-cfec-4a27-b64e-c8eda7dcedca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[40, 'per:place_of_death'], 2000대\n",
    "#  [48, 'org:number_of_employees/members'], 2000대\n",
    "#  [66, 'org:dissolved'], 2000대\n",
    "#  [82, 'per:schools_attended'], 2000대\n",
    "#  [96, 'per:religion'], (2196, 6)\n",
    "#  [98, 'org:political/religious_affiliation'], (2296, 6)\n",
    "#  [136, 'per:siblings'], (2040, 6)\n",
    "#  [139, 'per:product'], (2224, 6)\n",
    "#  [155, 'org:founded_by'], (2015, 6)\n",
    "#  [166, 'per:place_of_birth'], (2158, 6)\n",
    "#  [190, 'per:other_family'], (2090, 6)\n",
    "#  [193, 'per:place_of_residence'], (2123, 6)\n",
    "#  [304, 'per:children'], (2128, 6)\n",
    "#  [380, 'org:product'], (2280, 6)\n",
    "#  [418, 'per:date_of_death'], (2090, 6)\n",
    "#  [420, 'org:members'], (1260, 6)\n",
    "#  [450, 'org:founded'], (2250, 6)\n",
    "#  [520, 'per:parents'], (2080, 6)\n",
    "#  [534, 'per:colleagues'], (2136, 6)\n",
    "#  [795, 'per:spouse'], (2385, 6)\n",
    "#  [1001, 'per:alternate_names'], (1001, 6)\n",
    "#  [1130, 'per:date_of_birth'],\n",
    "#  [1195, 'org:place_of_headquarters'],\n",
    "#  [1234, 'per:origin'],\n",
    "#  [1320, 'org:alternate_names'],\n",
    "#  [1866, 'org:member_of'],\n",
    "#  [2103, 'per:title'],\n",
    "#  [3573, 'per:employee_of'],\n",
    "#  [4284, 'org:top_members/employees'],\n",
    "#  [9534, 'no_relation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6902909e-2e1e-4ab7-bed4-580b555316f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32470, 6)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./train/train.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1d61fd5a-f2b8-41d4-80a7-78e9ea24288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orgs = pd.read_csv('./object_ORG_list.csv') # or extract_entity_based_on_type(data, 'subject_entity' ,'ORG')\n",
    "dats = pd.read_csv('./object_DAT_list.csv') # or extract_entity_based_on_type(data, 'object_entity' ,'DAT')\n",
    "pers = pd.read_csv('./object_PER_list.csv') # or extract_entity_based_on_type(data, 'subject_entity' ,'PER')\n",
    "locs = pd.read_csv('./object_LOC_list.csv') # or extract_entity_based_on_type(data, 'subject_entity' ,'LOC')\n",
    "nohs = pd.read_csv('./object_NOH_list.csv') # or extract_entity_based_on_type(data, 'object_entity' ,'NOH')\n",
    "pros= pd.read_csv('./object_product_list.csv.csv')\n",
    "religion = pd.read_csv('./object_Religion_list.csv.csv')\n",
    "school = pd.read_csv('./object_school_list.csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "bef2427f-c237-4e44-88f1-a65ca2f06c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 'per:place_of_death'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "72b705be-fc56-4530-bd37-87baae9e77df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 6)\n"
     ]
    }
   ],
   "source": [
    "target_df = data.loc[data.label == target_label]\n",
    "print(target_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e5afe2b0-f057-4b23-899b-52dbafc798e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pohs = extract_entity_based_on_type(target_df, 'object_entity', 'POH', './object_orgproduct_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8e30071e-4ec1-4a69-82f2-40feb3ebf041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 데이터 수: (2000, 6)\n"
     ]
    }
   ],
   "source": [
    "new_df = augment_data(target_df, pers, dats, target_label, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14b4c6-4540-439c-8a24-ec940bc7683f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "68610a5c-dd08-4eb6-a4f0-ed35fd8e05ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 데이터 수: (2480, 6)\n",
      "생성된 데이터 수: (2496, 6)\n",
      "생성된 데이터 수: (2442, 6)\n",
      "생성된 데이터 수: (2460, 6)\n",
      "생성된 데이터 수: (2496, 6)\n",
      "생성된 데이터 수: (2450, 6)\n",
      "생성된 데이터 수: (1904, 6)\n",
      "생성된 데이터 수: (1946, 6)\n",
      "생성된 데이터 수: (1860, 6)\n",
      "생성된 데이터 수: (1992, 6)\n",
      "생성된 데이터 수: (1900, 6)\n",
      "생성된 데이터 수: (1930, 6)\n",
      "생성된 데이터 수: (1824, 6)\n",
      "생성된 데이터 수: (1900, 6)\n",
      "생성된 데이터 수: (1672, 6)\n",
      "생성된 데이터 수: (1680, 6)\n",
      "생성된 데이터 수: (1800, 6)\n",
      "생성된 데이터 수: (1560, 6)\n",
      "생성된 데이터 수: (1068, 6)\n",
      "생성된 데이터 수: (795, 6)\n",
      "생성된 데이터 수: (1001, 6)\n",
      "생성된 데이터 수: (1130, 6)\n",
      "생성된 데이터 수: (1195, 6)\n",
      "생성된 데이터 수: (1234, 6)\n",
      "생성된 데이터 수: (1320, 6)\n"
     ]
    }
   ],
   "source": [
    "target_label = 'per:place_of_death'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, dats, target_label, 2500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:number_of_employees/members'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, orgs, nohs, target_label, 2500//len(target_df), f'new_org:number_of_employees_members.csv')\n",
    "\n",
    "target_label = 'org:dissolved'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, orgs, dats, target_label, 2500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:schools_attended'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, school, target_label, 2500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:religion'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, religion, target_label, 2500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:political/religious_affiliation'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "pohs = extract_entity_based_on_type(target_df, 'object_entity', 'POH', './religious_affiliation_list.csv')\n",
    "new_df = augment_data(target_df, orgs, pohs, target_label, 2500//len(target_df), f'new_org:political_religious_affiliation')\n",
    "\n",
    "target_label = 'per:siblings'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pers, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:product'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pros, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:founded_by'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, orgs, orgs, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:place_of_birth'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, locs, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:other_family'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pers, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:place_of_residence'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, locs, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:children'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pers, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:product'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "pohs = extract_entity_based_on_type(target_df, 'object_entity', 'POH', './org:product_list.csv')\n",
    "new_df = augment_data(target_df, orgs, pohs, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:date_of_death'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, dats, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:members'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, orgs, orgs, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:founded'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, orgs, dats, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:parents'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pers, target_label, 2000//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:colleagues'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pers, target_label, 1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:spouse'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pers, target_label, 1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:alternate_names'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, pers, target_label, 1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:date_of_birth'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, dats, target_label,1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:place_of_headquarters'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, orgs, locs, target_label, 1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'per:origin'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, pers, locs, target_label, 1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "target_label = 'org:alternate_names'\n",
    "target_df = data.loc[data.label == target_label]\n",
    "new_df = augment_data(target_df, orgs, orgs, target_label, 1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "# target_label = 'org:member_of'\n",
    "# target_df = data.loc[data.label == target_label]\n",
    "# new_df = augment_data(target_df, orgs, orgs, target_label, 1500//len(target_df), f'new_{target_label}.csv')\n",
    "\n",
    "# target_label = 'per:title'\n",
    "# target_df = data.loc[data.label == target_label]\n",
    "# pohs = extract_entity_based_on_type(target_df, 'object_entity', 'POH', './titles.csv')\n",
    "# new_df = augment_data(target_df, pers, pohs, target_label, 1500//len(target_df), f'new_{target_label}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc166fc-954d-48a5-8621-c7b93e29eda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f0d85d6-aeec-4ac3-90a4-ddc79bc3f0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>앨리슨 슈밋</td>\n",
       "      <td>PER</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>강명도</td>\n",
       "      <td>PER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>윤종신</td>\n",
       "      <td>PER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>미유키</td>\n",
       "      <td>PER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>테드 크루즈</td>\n",
       "      <td>PER</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7399</th>\n",
       "      <td>모리에 히로시</td>\n",
       "      <td>PER</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>남창희</td>\n",
       "      <td>PER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7401</th>\n",
       "      <td>딥플로우</td>\n",
       "      <td>PER</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7402</th>\n",
       "      <td>오준혁</td>\n",
       "      <td>PER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7403</th>\n",
       "      <td>허용준</td>\n",
       "      <td>PER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7404 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         name type  length\n",
       "0      앨리슨 슈밋  PER       6\n",
       "1         강명도  PER       3\n",
       "2         윤종신  PER       3\n",
       "3         미유키  PER       3\n",
       "4      테드 크루즈  PER       6\n",
       "...       ...  ...     ...\n",
       "7399  모리에 히로시  PER       7\n",
       "7400      남창희  PER       3\n",
       "7401     딥플로우  PER       4\n",
       "7402      오준혁  PER       3\n",
       "7403      허용준  PER       3\n",
       "\n",
       "[7404 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4dd3ef-628a-470c-827e-427dee52a996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
