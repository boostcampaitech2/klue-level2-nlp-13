{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de431c0d-8ec3-4763-8b56-f4bbb860a782",
   "metadata": {},
   "source": [
    "# Using special token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3e1c51-cc6c-4e44-925b-deb5f85672a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd5afaa-a1de-4bd5-9580-7ce059b6e0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_config =  AutoConfig.from_pretrained('klue/bert-base')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('klue/bert-base', config=model_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909b9ab7-d8f4-4e33-8f18-80493dc6de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def preprocessing_dataset(dataset):\n",
    "    \"\"\" 처음 불러온 csv 파일을 원하는 형태의 DataFrame으로 변경 시켜줍니다.\"\"\"\n",
    "    subject_word, subject_idx, subject_type = [], [], []\n",
    "    object_word, object_idx, object_type = [], [], []\n",
    "\n",
    "    for subject_entity, object_entity in zip(dataset['subject_entity'], dataset['object_entity']):\n",
    "        subject_dict = eval(subject_entity)\n",
    "        object_dict = eval(object_entity)\n",
    "\n",
    "        subject_word.append(subject_dict['word'])\n",
    "        subject_idx.append((subject_dict['start_idx'], subject_dict['end_idx']))\n",
    "        subject_type.append(subject_dict['type'])\n",
    "        object_word.append(object_dict['word'])\n",
    "        object_idx.append((object_dict['start_idx'], object_dict['end_idx']))\n",
    "        object_type.append(object_dict['type'])\n",
    "\n",
    "    out_dataset = pd.DataFrame({\n",
    "        'id': dataset['id'], \n",
    "        'sentence': dataset['sentence'],\n",
    "        'subject_word': subject_word,\n",
    "        'subject_idx': subject_idx,\n",
    "        'subject_type': subject_type,\n",
    "        'object_word': object_word,\n",
    "        'object_idx': object_idx,\n",
    "        'object_type': object_type,\n",
    "        'label': dataset['label'],\n",
    "        'source': dataset['source']\n",
    "    })\n",
    "\n",
    "    return out_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8779a9cc-5df1-4772-a942-66ca4c37b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dataset = pd.read_csv('../../../dataset/train/train.csv')\n",
    "dataset = preprocessing_dataset(pd_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fa1c3f2-71bd-41e0-a64b-6f7fe799f34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_word</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>subject_type</th>\n",
       "      <th>object_word</th>\n",
       "      <th>object_idx</th>\n",
       "      <th>object_type</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>비틀즈</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>조지 해리슨</td>\n",
       "      <td>(13, 18)</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>민주평화당</td>\n",
       "      <td>(19, 23)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>대안신당</td>\n",
       "      <td>(14, 17)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...</td>\n",
       "      <td>광주FC</td>\n",
       "      <td>(21, 24)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>한국프로축구연맹</td>\n",
       "      <td>(34, 41)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...</td>\n",
       "      <td>아성다이소</td>\n",
       "      <td>(13, 17)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>박정부</td>\n",
       "      <td>(22, 24)</td>\n",
       "      <td>PER</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...</td>\n",
       "      <td>요미우리 자이언츠</td>\n",
       "      <td>(22, 30)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1967</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>DAT</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence subject_word  \\\n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...          비틀즈   \n",
       "1   1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...        민주평화당   \n",
       "2   2  K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...         광주FC   \n",
       "3   3  균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...        아성다이소   \n",
       "4   4  1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...    요미우리 자이언츠   \n",
       "\n",
       "  subject_idx subject_type object_word object_idx object_type  \\\n",
       "0    (24, 26)          ORG      조지 해리슨   (13, 18)         PER   \n",
       "1    (19, 23)          ORG        대안신당   (14, 17)         ORG   \n",
       "2    (21, 24)          ORG    한국프로축구연맹   (34, 41)         ORG   \n",
       "3    (13, 17)          ORG         박정부   (22, 24)         PER   \n",
       "4    (22, 30)          ORG        1967     (0, 3)         DAT   \n",
       "\n",
       "                       label     source  \n",
       "0                no_relation  wikipedia  \n",
       "1                no_relation   wikitree  \n",
       "2              org:member_of   wikitree  \n",
       "3  org:top_members/employees   wikitree  \n",
       "4                no_relation  wikipedia  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fbc69b4-57b2-4b55-997b-c4ac8f15dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "\n",
    "def label_to_num(file_path, label):\n",
    "    num_label = []\n",
    "    with open(file_path, 'rb') as f:\n",
    "        dict_label_to_num = pickle.load(f)\n",
    "    for v in label:\n",
    "        num_label.append(dict_label_to_num[v])\n",
    "\n",
    "    return num_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6dc6da2-5b75-412f-92f8-d27541048576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 20, 1, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset\n",
    "train_label = label_to_num('../dict_label_to_num.pkl', train_dataset['label'].values) \n",
    "train_label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9858b36f-b9c0-404b-a2e2-f5f27ec54045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_word</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>subject_type</th>\n",
       "      <th>object_word</th>\n",
       "      <th>object_idx</th>\n",
       "      <th>object_type</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>비틀즈</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>조지 해리슨</td>\n",
       "      <td>(13, 18)</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>민주평화당</td>\n",
       "      <td>(19, 23)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>대안신당</td>\n",
       "      <td>(14, 17)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...</td>\n",
       "      <td>광주FC</td>\n",
       "      <td>(21, 24)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>한국프로축구연맹</td>\n",
       "      <td>(34, 41)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...</td>\n",
       "      <td>아성다이소</td>\n",
       "      <td>(13, 17)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>박정부</td>\n",
       "      <td>(22, 24)</td>\n",
       "      <td>PER</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...</td>\n",
       "      <td>요미우리 자이언츠</td>\n",
       "      <td>(22, 30)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1967</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>DAT</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence subject_word  \\\n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...          비틀즈   \n",
       "1   1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...        민주평화당   \n",
       "2   2  K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...         광주FC   \n",
       "3   3  균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...        아성다이소   \n",
       "4   4  1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...    요미우리 자이언츠   \n",
       "\n",
       "  subject_idx subject_type object_word object_idx object_type  \\\n",
       "0    (24, 26)          ORG      조지 해리슨   (13, 18)         PER   \n",
       "1    (19, 23)          ORG        대안신당   (14, 17)         ORG   \n",
       "2    (21, 24)          ORG    한국프로축구연맹   (34, 41)         ORG   \n",
       "3    (13, 17)          ORG         박정부   (22, 24)         PER   \n",
       "4    (22, 30)          ORG        1967     (0, 3)         DAT   \n",
       "\n",
       "                       label     source  \n",
       "0                no_relation  wikipedia  \n",
       "1                no_relation   wikitree  \n",
       "2              org:member_of   wikitree  \n",
       "3  org:top_members/employees   wikitree  \n",
       "4                no_relation  wikipedia  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86f7fe81-b619-416a-9373-e2c4fb991ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_dataset(dataset, tokenizer):\n",
    "    \"\"\" tokenizer에 따라 sentence를 tokenizing 합니다.\"\"\"\n",
    "    concat_entity = []\n",
    "    for e01, e02 in zip(dataset['subject_word'], dataset['object_word']):\n",
    "        temp = ''\n",
    "        temp = e01 + '[SEP]' + e02\n",
    "        concat_entity.append(temp)\n",
    "    tokenized_sentences = tokenizer(\n",
    "          concat_entity,\n",
    "          list(dataset['sentence']),\n",
    "          return_tensors=\"pt\",\n",
    "          padding=True,\n",
    "          truncation=True,\n",
    "          max_length=256,\n",
    "          add_special_tokens=True,\n",
    "          #return_token_type_ids=False,\n",
    "    )\n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa27bc93-1845-4c15-a16b-ec622847b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenized_dataset(train_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0db2ca74-c500-4ef1-858b-299783332f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '비틀즈', '[SEP]', '조지', '해리', '##슨', '[SEP]', '〈', 'So', '##me']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train[0].tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72b48e4d-0007-4533-8f08-b2f34e6d5092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_word</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>subject_type</th>\n",
       "      <th>object_word</th>\n",
       "      <th>object_idx</th>\n",
       "      <th>object_type</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>비틀즈</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>조지 해리슨</td>\n",
       "      <td>(13, 18)</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence subject_word  \\\n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...          비틀즈   \n",
       "\n",
       "  subject_idx subject_type object_word object_idx object_type        label  \\\n",
       "0    (24, 26)          ORG      조지 해리슨   (13, 18)         PER  no_relation   \n",
       "\n",
       "      source  \n",
       "0  wikipedia  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c6c423ff-1434-447f-b2e9-ab77b82d0e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "〈Something〉는 [PER]조지 해리슨[/PER]이 쓰고 [ORG]비틀즈[/ORG]가 1969년 앨범 《Abbey Road》에 담은 노래다.\n"
     ]
    }
   ],
   "source": [
    "if dataset[\"subject_idx\"][0] > dataset[\"object_idx\"][0]:\n",
    "    print(dataset[\"sentence\"][0][:dataset[\"object_idx\"][0][0]]\n",
    "          + f'[{dataset[\"object_type\"][0]}]' + dataset['object_word'][0] + f'[/{dataset[\"object_type\"][0]}]'\n",
    "          + dataset[\"sentence\"][0][dataset[\"object_idx\"][0][1]+1:dataset[\"subject_idx\"][0][0]]\n",
    "          + f'[{dataset[\"subject_type\"][0]}]' + dataset['subject_word'][0] + f'[/{dataset[\"subject_type\"][0]}]'\n",
    "          + dataset[\"sentence\"][0][dataset[\"subject_idx\"][0][1]+1:]\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944b528-f7db-4c76-8f83-d500af0a3af4",
   "metadata": {},
   "source": [
    "## Typed entity marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "14486344-966a-4ff8-9a63-e8530bc02f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_dataset_custom(dataset, tokenizer):\n",
    "    sentence_list = []\n",
    "    seperate_token = '[SEP]'\n",
    "    for s_word, s_type, s_idx, o_word, o_type, o_idx, sentence in zip(dataset['subject_word'], dataset['subject_type'], dataset['subject_idx'],\n",
    "                                                                        dataset['object_word'], dataset['object_type'], dataset['object_idx'], dataset['sentence']):\n",
    "        # s_idx = eval(s_idx)\n",
    "        # o_idx = eval(o_idx)\n",
    "        if s_idx > o_idx:\n",
    "            sentence_list.append(sentence[:o_idx[0]] + f'<O:{o_type}>' + o_word + f'</O:{o_type}>' + sentence[o_idx[1]+1:s_idx[0]] \\\n",
    "                                 + seperate_token + f'<S:{s_type}>' + s_word + f'</S:{s_type}>' + sentence[s_idx[1]+1:])\n",
    "        else:\n",
    "            sentence_list.append(sentence[:s_idx[0]] + f'<S:{s_type}>' + s_word + f'</S:{s_type}>' + sentence[s_idx[1]+1:o_idx[0]] \\\n",
    "                                 + seperate_token + f'<O:{o_type}>' + o_word + f'</O:{o_type}>' + sentence[o_idx[1]+1:])\n",
    "\n",
    "\n",
    "    tokenized_sentences = tokenizer(\n",
    "        sentence_list,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        add_special_tokens=True,\n",
    "        #return_token_type_ids=False, # 문장 id\n",
    "    )\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2c35b6c2-0ee3-4170-aa3b-546afdc5bf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,   168, 30985,  ...,     0,     0,     0],\n",
       "        [    2,  6409,  2052,  ...,     0,     0,     0],\n",
       "        [    2,    47, 17665,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,    32,    55,  ...,     0,     0,     0],\n",
       "        [    2, 15724,    16,  ...,     0,     0,     0],\n",
       "        [    2,    32,    55,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train = tokenized_dataset_custom(dataset, tokenizer)\n",
    "tokenized_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2de9832e-017a-471d-830e-c78ba2cbaf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': ['<S:PER>','<S:ORG>','<S:POH>','<S:DAT>','<S:LOC>','<S:NOH>','<O:PER>','<O:ORG>','<O:POH>','<O:DAT>','<O:LOC>','<O:NOH>','</S:PER>','</S:ORG>','</S:POH>','</S:DAT>','</S:LOC>','</S:NOH>','</O:PER>','</O:ORG>','</O:POH>','</O:DAT>','</O:LOC>','</O:NOH>']}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "632134d9-ebed-4e1e-92b2-638cfd438823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='klue/bert-base', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['<S:PER>', '<S:ORG>', '<S:POH>', '<S:DAT>', '<S:LOC>', '<S:NOH>', '<O:PER>', '<O:ORG>', '<O:POH>', '<O:DAT>', '<O:LOC>', '<O:NOH>', '</S:PER>', '</S:ORG>', '</S:POH>', '</S:DAT>', '</S:LOC>', '</S:NOH>', '</O:PER>', '</O:ORG>', '</O:POH>', '</O:DAT>', '</O:LOC>', '</O:NOH>']})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e315b016-b972-4569-b670-e4f75b9060b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 168, 30985, 14451, 7088, 4586, 169, 793, 8373, 14113, 2234, 2052, 1363, 2088, 29830, 2116, 14879, 2440, 6711, 170, 21406, 26713, 2076, 25145, 5749, 171, 1421, 818, 2073, 4388, 2062, 18, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 〈 Something 〉 는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《 Abbey Road 》 에 담은 노래다. [SEP]'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.encode(train_dataset.sentence.iloc[0]))\n",
    "#print(tokenizer.encode(train_dataset.sentence.iloc[0]).token_type_ids)\n",
    "tokenizer.decode(tokenizer.encode(train_dataset.sentence.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22a9d7fa-db2d-4d3e-b6da-77c46fd424e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RE_Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Dataset 구성을 위한 class.\"\"\"\n",
    "    def __init__(self, pair_dataset, labels):\n",
    "        self.pair_dataset = pair_dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.pair_dataset.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24b81fb2-b32a-434f-b3e1-0e8498a8c9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_train_dataset = RE_Dataset(tokenized_train, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55248e41-348f-407b-b908-e873507ac961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32005, 768)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538cf49d-ebc4-43be-b485-1a25e1460699",
   "metadata": {},
   "source": [
    "## Typed entity marker Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5cb25f8b-f274-48ab-92c7-d127b8c43336",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2926d4e4-dc65-4742-a79c-293fa07afb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_dataset_custom(dataset, tokenizer):\n",
    "    sentence_list = []\n",
    "\n",
    "    for s_word, s_type, s_idx, o_word, o_type, o_idx, sentence in zip(dataset['subject_word'], dataset['subject_type'], dataset['subject_idx'],\n",
    "                                                                        dataset['object_word'], dataset['object_type'], dataset['object_idx'], dataset['sentence']):\n",
    "        # s_idx = eval(s_idx)\n",
    "        # o_idx = eval(o_idx)\n",
    "        if s_idx > o_idx:\n",
    "            sentence_list.append(sentence[:o_idx[0]] + f' # ∧ [{o_type}] ∧ {o_word} # ' + sentence[o_idx[1]+1:s_idx[0]] \\\n",
    "                                 + f' @ * {s_type} * {s_word} @ ' + sentence[s_idx[1]+1:])\n",
    "        else:\n",
    "            sentence_list.append(sentence[:s_idx[0]] + f' @ * {s_type} * {s_word} @ ' + sentence[s_idx[1]+1:o_idx[0]] \\\n",
    "                                 + f' # ∧ {o_type} ∧ {o_word} # ' + sentence[o_idx[1]+1:])\n",
    "\n",
    "    print(sentence_list[0])\n",
    "    tokenized_sentences = tokenizer(\n",
    "        sentence_list,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        add_special_tokens=True,\n",
    "        #return_token_type_ids=False, # 문장 id\n",
    "    )\n",
    "    \n",
    "    return tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b576ac1d-9ee1-4b66-b42f-ef40a4167ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='klue/roberta-large', vocab_size=32000, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]', 'additional_special_tokens': ['[PER]', 'ORG', 'LOC', 'POH', 'NOH', 'DAT']})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_tokens_dict = {'additional_special_tokens': ['[PER]', 'ORG', 'LOC', 'POH', 'NOH', 'DAT']}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "174585d5-eba7-479f-8326-201ddad588c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "〈Something〉는  # ∧ [PER] ∧ 조지 해리슨 # 이 쓰고  @ * ORG * 비틀즈 @ 가 1969년 앨범 《Abbey Road》에 담은 노래다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 〈 Something 〉 는 # [UNK] [ PER ] [UNK] 조지 해리슨 # 이 쓰고 @ * ORG * 비틀즈 @ 가 1969년 앨범 《 Abbey Road 》 에 담은 노래다. [SEP]'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_dataset_custom(dataset.head(1), tokenizer).input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4315f-f702-49c8-a9c9-8a59f7fd7611",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset 정제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ee62c9a-003e-4482-a03d-69a368d80af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_dataset = pd.read_csv('../../../dataset/train/train.csv')\n",
    "dataset = preprocessing_dataset(pd_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6fdd683f-c36c-4a7b-9d77-1d83b6aa79e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_word</th>\n",
       "      <th>subject_idx</th>\n",
       "      <th>subject_type</th>\n",
       "      <th>object_word</th>\n",
       "      <th>object_idx</th>\n",
       "      <th>object_type</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...</td>\n",
       "      <td>비틀즈</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>조지 해리슨</td>\n",
       "      <td>(13, 18)</td>\n",
       "      <td>PER</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...</td>\n",
       "      <td>민주평화당</td>\n",
       "      <td>(19, 23)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>대안신당</td>\n",
       "      <td>(14, 17)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...</td>\n",
       "      <td>광주FC</td>\n",
       "      <td>(21, 24)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>한국프로축구연맹</td>\n",
       "      <td>(34, 41)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>org:member_of</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...</td>\n",
       "      <td>아성다이소</td>\n",
       "      <td>(13, 17)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>박정부</td>\n",
       "      <td>(22, 24)</td>\n",
       "      <td>PER</td>\n",
       "      <td>org:top_members/employees</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...</td>\n",
       "      <td>요미우리 자이언츠</td>\n",
       "      <td>(22, 30)</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1967</td>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>DAT</td>\n",
       "      <td>no_relation</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           sentence subject_word  \\\n",
       "0   0  〈Something〉는 조지 해리슨이 쓰고 비틀즈가 1969년 앨범 《Abbey R...          비틀즈   \n",
       "1   1  호남이 기반인 바른미래당·대안신당·민주평화당이 우여곡절 끝에 합당해 민생당(가칭)으...        민주평화당   \n",
       "2   2  K리그2에서 성적 1위를 달리고 있는 광주FC는 지난 26일 한국프로축구연맹으로부터...         광주FC   \n",
       "3   3  균일가 생활용품점 (주)아성다이소(대표 박정부)는 코로나19 바이러스로 어려움을 겪...        아성다이소   \n",
       "4   4  1967년 프로 야구 드래프트 1순위로 요미우리 자이언츠에게 입단하면서 등번호는 8...    요미우리 자이언츠   \n",
       "\n",
       "  subject_idx subject_type object_word object_idx object_type  \\\n",
       "0    (24, 26)          ORG      조지 해리슨   (13, 18)         PER   \n",
       "1    (19, 23)          ORG        대안신당   (14, 17)         ORG   \n",
       "2    (21, 24)          ORG    한국프로축구연맹   (34, 41)         ORG   \n",
       "3    (13, 17)          ORG         박정부   (22, 24)         PER   \n",
       "4    (22, 30)          ORG        1967     (0, 3)         DAT   \n",
       "\n",
       "                       label     source  \n",
       "0                no_relation  wikipedia  \n",
       "1                no_relation   wikitree  \n",
       "2              org:member_of   wikitree  \n",
       "3  org:top_members/employees   wikitree  \n",
       "4                no_relation  wikipedia  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50f3d760-416a-4eb0-8886-05195589af4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         {'word': 'MBC', 'start_idx': 7, 'end_idx': 9, 'type': 'ORG'}\n",
       "1    {'word': '프린세스 프링', 'start_idx': 7, 'end_idx': 13, 'type': 'PER'}\n",
       "2      {'word': '경찰', 'start_idx': 121, 'end_idx': 122, 'type': 'ORG'}\n",
       "3        {'word': '세조', 'start_idx': 78, 'end_idx': 79, 'type': 'PER'}\n",
       "4         {'word': '민주당', 'start_idx': 3, 'end_idx': 5, 'type': 'ORG'}\n",
       "Name: subject_entity, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max.colwidth', 2000)\n",
    "test_data = pd.read_csv('../../../dataset/test/test_data.csv')\n",
    "test_data.subject_entity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "eff80056-c168-408a-aea9-dd8cc738d0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>subject_entity</th>\n",
       "      <th>object_entity</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>지난 15일 MBC '탐사기획 스트레이트'가 이 사실을 보도했다.</td>\n",
       "      <td>{'word': 'MBC', 'start_idx': 7, 'end_idx': 9, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '탐사기획 스트레이트', 'start_idx': 12, 'end_idx': 21, 'type': 'ORG'}</td>\n",
       "      <td>100</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>사랑스러운 ‘프린세스 프링’의 이름은 봄의 공주님: Princess(s)Pring이란 뜻으로 탄생, 부활, 청춘 등 여러 가지 의미를 담아 생일왕국의 공주님의 이름이 되었다.</td>\n",
       "      <td>{'word': '프린세스 프링', 'start_idx': 7, 'end_idx': 13, 'type': 'PER'}</td>\n",
       "      <td>{'word': '공주', 'start_idx': 84, 'end_idx': 85, 'type': 'POH'}</td>\n",
       "      <td>100</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>한편, 본인(이근안)을 모델로 한 MBC 특집드라마 가 1995년 6.25 특집극으로 편성될 예정이었는데 제작비 문제 때문에 연출자 고석만 PD(당시 단막극 팀장)가 MBC에 지원을 요청했지만 거절당한 데다 MBC가 경찰과의 관계 약화를 염려하여 제작을 달갑지 않게 여겼고 이 과정에서 연출자가 1995년 3월 29일 MBC에 사표를 제출한 후 프리랜서를 선언하여 편성이 무산됐으며 고석만 PD는 의 제작과 관련한 MBC와의 마찰 외에도 1994년 10월 \"평프로듀서로 일하고 싶다\"며 당시 맡고 있던 단막극 책임PD(종합병원 전원일기 등등) 보직 사퇴의사를 밝혔지만 MBC 측의 반대로 무산되자 프리랜서를 선언했다.</td>\n",
       "      <td>{'word': '경찰', 'start_idx': 121, 'end_idx': 122, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '1995년', 'start_idx': 31, 'end_idx': 35, 'type': 'DAT'}</td>\n",
       "      <td>100</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>정창손은 김질과 같이 대궐로 달려가 고변하며 '신은 실로 모르고 김질만 혼자 참여하였는데, 김질의 죄는 만번 죽어 마땅합니다.'라고 하니, 세조가 특별히 김질을 사면하였다.</td>\n",
       "      <td>{'word': '세조', 'start_idx': 78, 'end_idx': 79, 'type': 'PER'}</td>\n",
       "      <td>{'word': '정창손', 'start_idx': 0, 'end_idx': 2, 'type': 'PER'}</td>\n",
       "      <td>100</td>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>당시 민주당 이진련 시의원은 권영진 시장에게 \"긴급 생계자금을 왜 현금으로 지원하지 않느냐\"고 따졌다.</td>\n",
       "      <td>{'word': '민주당', 'start_idx': 3, 'end_idx': 5, 'type': 'ORG'}</td>\n",
       "      <td>{'word': '권영진', 'start_idx': 16, 'end_idx': 18, 'type': 'PER'}</td>\n",
       "      <td>100</td>\n",
       "      <td>wikitree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0   0   \n",
       "1   1   \n",
       "2   2   \n",
       "3   3   \n",
       "4   4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                    sentence  \\\n",
       "0                                                                                                                                                                                                                                                                                                                       지난 15일 MBC '탐사기획 스트레이트'가 이 사실을 보도했다.   \n",
       "1                                                                                                                                                                                                                                                          사랑스러운 ‘프린세스 프링’의 이름은 봄의 공주님: Princess(s)Pring이란 뜻으로 탄생, 부활, 청춘 등 여러 가지 의미를 담아 생일왕국의 공주님의 이름이 되었다.   \n",
       "2  한편, 본인(이근안)을 모델로 한 MBC 특집드라마 가 1995년 6.25 특집극으로 편성될 예정이었는데 제작비 문제 때문에 연출자 고석만 PD(당시 단막극 팀장)가 MBC에 지원을 요청했지만 거절당한 데다 MBC가 경찰과의 관계 약화를 염려하여 제작을 달갑지 않게 여겼고 이 과정에서 연출자가 1995년 3월 29일 MBC에 사표를 제출한 후 프리랜서를 선언하여 편성이 무산됐으며 고석만 PD는 의 제작과 관련한 MBC와의 마찰 외에도 1994년 10월 \"평프로듀서로 일하고 싶다\"며 당시 맡고 있던 단막극 책임PD(종합병원 전원일기 등등) 보직 사퇴의사를 밝혔지만 MBC 측의 반대로 무산되자 프리랜서를 선언했다.   \n",
       "3                                                                                                                                                                                                                                                           정창손은 김질과 같이 대궐로 달려가 고변하며 '신은 실로 모르고 김질만 혼자 참여하였는데, 김질의 죄는 만번 죽어 마땅합니다.'라고 하니, 세조가 특별히 김질을 사면하였다.   \n",
       "4                                                                                                                                                                                                                                                                                                  당시 민주당 이진련 시의원은 권영진 시장에게 \"긴급 생계자금을 왜 현금으로 지원하지 않느냐\"고 따졌다.   \n",
       "\n",
       "                                                      subject_entity  \\\n",
       "0       {'word': 'MBC', 'start_idx': 7, 'end_idx': 9, 'type': 'ORG'}   \n",
       "1  {'word': '프린세스 프링', 'start_idx': 7, 'end_idx': 13, 'type': 'PER'}   \n",
       "2    {'word': '경찰', 'start_idx': 121, 'end_idx': 122, 'type': 'ORG'}   \n",
       "3      {'word': '세조', 'start_idx': 78, 'end_idx': 79, 'type': 'PER'}   \n",
       "4       {'word': '민주당', 'start_idx': 3, 'end_idx': 5, 'type': 'ORG'}   \n",
       "\n",
       "                                                           object_entity  \\\n",
       "0  {'word': '탐사기획 스트레이트', 'start_idx': 12, 'end_idx': 21, 'type': 'ORG'}   \n",
       "1          {'word': '공주', 'start_idx': 84, 'end_idx': 85, 'type': 'POH'}   \n",
       "2       {'word': '1995년', 'start_idx': 31, 'end_idx': 35, 'type': 'DAT'}   \n",
       "3           {'word': '정창손', 'start_idx': 0, 'end_idx': 2, 'type': 'PER'}   \n",
       "4         {'word': '권영진', 'start_idx': 16, 'end_idx': 18, 'type': 'PER'}   \n",
       "\n",
       "   label     source  \n",
       "0    100   wikitree  \n",
       "1    100  wikipedia  \n",
       "2    100  wikipedia  \n",
       "3    100  wikipedia  \n",
       "4    100   wikitree  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f1a9e311-1b22-433a-b527-450cd6998638",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_check = 'per:children'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dd945227-6795-428d-aa84-ec6d51bc31e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.object_type.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b0c30b5-90a0-4d97-a784-55bb87e069c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_csv = pd.read_csv('../../../dataset/train/train_dataset.csv')\n",
    "temp_add_csv = pd.read_csv('../../../dataset/train/additional_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922d365-42ba-4187-b87f-673502c01693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
